{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Question_Answer_Dataset_Sequence_to_Sequence_using_Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divya-r-kamat/END/blob/main/Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate/Question_Answer/Question_Answer_Dataset_Sequence_to_Sequence_using_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C-PE8R83XdV"
      },
      "source": [
        "# Neural Machine Translation by Jointly Learning to Align and Translate\r\n",
        "\r\n",
        "In this notebook on sequence-to-sequence models using PyTorch and TorchText, we'll be implementing the model from [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473). \r\n",
        "## Introduction\r\n",
        "\r\n",
        "As a reminder, here is the general encoder-decoder model:\r\n",
        "\r\n",
        "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq1.png?raw=1)\r\n",
        "\r\n",
        "In the previous model, our architecture was set-up in a way to reduce \"information compression\" by explicitly passing the context vector, $z$, to the decoder at every time-step and by passing both the context vector and embedded input word, $d(y_t)$, along with the hidden state, $s_t$, to the linear layer, $f$, to make a prediction.\r\n",
        "\r\n",
        "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq7.png?raw=1)\r\n",
        "\r\n",
        "Even though we have reduced some of this compression, our context vector still needs to contain all of the information about the source sentence. The model implemented in this notebook avoids this compression by allowing the decoder to look at the entire source sentence (via its hidden states) at each decoding step! How does it do this? It uses *attention*. \r\n",
        "\r\n",
        "Attention works by first, calculating an attention vector, $a$, that is the length of the source sentence. The attention vector has the property that each element is between 0 and 1, and the entire vector sums to 1. We then calculate a weighted sum of our source sentence hidden states, $H$, to get a weighted source vector, $w$. \r\n",
        "\r\n",
        "$$w = \\sum_{i}a_ih_i$$\r\n",
        "\r\n",
        "We calculate a new weighted source vector every time-step when decoding, using it as input to our decoder RNN as well as the linear layer to make a prediction. We'll explain how to do all of this during the session.\r\n",
        "\r\n",
        "## Preparing Data\r\n",
        "\r\n",
        "Again, the preparation is similar to last time.\r\n",
        "\r\n",
        "First we import all the required modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZv8dEzQwcay",
        "outputId": "086fd7f5-89e2-4334-f286-83c728fd73b3"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_cnrcYwdX-A",
        "outputId": "d27170da-49af-40e9-f966-93564ce15d7c"
      },
      "source": [
        "!ls \"/content/drive/MyDrive/Neural Machine Translation by Jointly Learning to Align and Translate/Question_Answer\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 01-Question_Answer_Dataset_Sequence_to_Sequence_using_Attention.ipynb\n",
            "'Copy of Question_Answer_Dataset_Sequence_to_Sequence_using_Attention.ipynb'\n",
            " data\n",
            " Readme.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7CXKYZ0fLaM",
        "outputId": "9651ca85-c6d9-41b8-a66e-1d3d419d33e3"
      },
      "source": [
        "!tar -xvf \"/content/drive/MyDrive/Neural Machine Translation by Jointly Learning to Align and Translate/Question_Answer/data/Question_Answer_Dataset_v1.2.tar.gz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question_Answer_Dataset_v1.2/\n",
            "Question_Answer_Dataset_v1.2/S08/\n",
            "Question_Answer_Dataset_v1.2/S08/question_answer_pairs.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a6.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a3.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a3.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a5.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a4o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a3.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a9.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a2.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a9.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a4.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a4.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a4.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a2.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a7o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a6.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a5o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a1o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a9o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a8.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a10.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a10.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a8.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/topics.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a2o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a8.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a7.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a1.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a2.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a10.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a10o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a6.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a7.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a9.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a6o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a8o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a1.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a1.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a7.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a5.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a5.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set4/a3o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a6.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a3.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a3.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a5.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a4o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a3.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a9.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a2.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a9.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a4.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a4.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a4.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a2.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a7o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a6.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a5o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a1o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a9o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a8.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a10.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a10.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a8.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/topics.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a2o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a8.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a7.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a1.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a2.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a10.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a10o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a6.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a7.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a9.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a6o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a8o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a1.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a1.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a7.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a5.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a5.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set3/a3o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a6.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a3.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a3.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a5.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a4o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a3.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a9.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a2.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a9.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a4.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a4.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a4.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a2.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a7o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a6.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a5o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a1o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a9o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a8.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a10.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a10.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a8.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/topics.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a2o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a8.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a7.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a1.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a2.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a10.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a10o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a6.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a7.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a9.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a6o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a8o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a1.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a1.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a7.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a5.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a5.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set2/a3o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a6.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a3.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a3.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a5.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a4o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a3.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a9.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a2.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a9.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a4.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a4.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a4.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a2.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a7o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a6.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a5o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a1o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a9o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a8.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a10.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a10.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a8.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/topics.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a2o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a8.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a7.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a1.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a2.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a10.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a10o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a6.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a7.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a9.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a6o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a8o.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a1.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a1.txt\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a7.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a5.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a5.htm\n",
            "Question_Answer_Dataset_v1.2/S08/data/set1/a3o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/\n",
            "Question_Answer_Dataset_v1.2/S10/question_answer_pairs.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a6.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a3.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a3.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a5.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a4o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a3.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a9.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a2.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a9.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a4.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a4.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a4.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a2.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a7o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a6.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a5o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a1o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a9o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a8.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a10.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a10.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a8.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/topics.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a2o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a8.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a7.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a1.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a2.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a10.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a10o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a6.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a7.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a9.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a6o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a8o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a1.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a1.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a7.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a5.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a5.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set6/a3o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a6.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a3.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a3.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a5.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a4o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a3.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a9.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a2.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a9.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a4.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a4.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a4.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a2.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a7o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a6.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a5o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a1o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a9o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a8.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a10.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a10.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a8.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/topics.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a2o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a8.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a7.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a1.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a2.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a10.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a10o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a6.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a7.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a9.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a6o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a8o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a1.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a1.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a7.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a5.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a5.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set4/a3o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a6.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a3.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a3.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a5.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a4o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a3.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a9.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a2.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a9.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a4.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a4.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a4.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a2.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a7o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a6.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a5o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a1o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a9o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a8.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a10.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a10.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a8.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/topics.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a2o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a8.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a7.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a1.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a2.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a10.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a10o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a6.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a7.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a9.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a6o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a8o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a1.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a1.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a7.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a5.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a5.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set3/a3o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a6.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a3.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a3.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a5.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a4o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a3.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a9.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a2.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a9.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a4.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a4.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a4.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a2.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a7o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a6.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a5o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a1o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a9o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a8.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a10.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a10.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a8.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/topics.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a2o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a8.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a7.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a1.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a2.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a10.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a10o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a6.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a7.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a9.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a6o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a8o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a1.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a1.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a7.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a5.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a5.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set2/a3o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a6.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a3.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a3.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a5.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a4o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a3.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a9.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a2.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a9.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a4.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a4.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a4.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a2.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a7o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a6.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a5o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a1o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a9o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a8.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a10.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a10.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a8.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/topics.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a2o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a8.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a7.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a1.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a2.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a10.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a10o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a6.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a7.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a9.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a6o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a8o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a1.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a1.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a7.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a5.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a5.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set5/a3o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a6.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a3.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a3.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a5.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a4o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a3.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a9.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a2.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a9.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a4.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a4.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a4.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a2.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a7o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a6.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a5o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a1o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a9o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a8.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a10.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a10.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a8.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/topics.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a2o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a8.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a7.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a1.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a2.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a10.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a10o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a6.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a7.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a9.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a6o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a8o.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a1.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a1.txt\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a7.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a5.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a5.htm\n",
            "Question_Answer_Dataset_v1.2/S10/data/set1/a3o.htm\n",
            "Question_Answer_Dataset_v1.2/LICENSE-S08,S09\n",
            "Question_Answer_Dataset_v1.2/README.v1.2\n",
            "Question_Answer_Dataset_v1.2/S09/\n",
            "Question_Answer_Dataset_v1.2/S09/question_answer_pairs.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a6.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a3.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a3.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a5.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a4o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a3.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a9.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a2.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a9.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a4.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a4.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a4.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a2.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a7o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a6.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a5o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a1o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a9o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a8.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a10.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a10.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a8.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/topics.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a2o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a8.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a7.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a1.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a2.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a10.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a10o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a6.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a7.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a9.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a6o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a8o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a1.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a1.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a7.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a5.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a5.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set4/a3o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a6.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a3.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a3.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a5.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a4o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a3.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a9.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a2.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a9.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a4.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a4.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a4.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a2.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a7o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a6.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a5o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a1o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a9o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a8.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a10.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a10.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a8.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/topics.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a2o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a8.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a7.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a1.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a2.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a10.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a10o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a6.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a7.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a9.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a6o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a8o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a1.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a1.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a7.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a5.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a5.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set3/a3o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a6.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a3.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a3.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a5.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a4o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a3.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a9.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a2.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a9.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a4.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a4.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a4.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a2.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a7o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a6.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a5o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a1o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a9o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a8.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a10.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a10.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a8.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/topics.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a2o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a8.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a7.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a1.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a2.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a10.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a10o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a6.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a7.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a9.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a6o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a8o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a1.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a1.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a7.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a5.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a5.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set2/a3o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a6.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a3.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a3.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a5.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a4o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a3.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a9.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a2.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a9.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a4.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a4.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a4.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a2.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a7o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a6.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a5o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a1o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a9o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a8.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a10.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a10.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a8.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/topics.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a2o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a8.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a7.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a1.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a2.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a10.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a10o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a6.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a7.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a9.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a6o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a8o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a1.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a1.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a7.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a5.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a5.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set5/a3o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a6.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a3.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a3.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a5.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a4o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a3.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a9.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a2.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a9.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a4.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a4.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a4.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a2.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a7o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a6.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a5o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a1o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a9o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a8.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a10.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a10.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a8.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/topics.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a2o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a8.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a7.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a1.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a2.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a10.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a10o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a6.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a7.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a9.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a6o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a8o.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a1.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a1.txt\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a7.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a5.txt.clean\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a5.htm\n",
            "Question_Answer_Dataset_v1.2/S09/data/set1/a3o.htm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysfsMhnWfQWs",
        "outputId": "fa5bc1c3-a610-4b11-f01b-a2f066854843"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  Question_Answer_Dataset_v1.2  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNhEtnaZfTAk"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c125yPZO8uJK"
      },
      "source": [
        "There are three directories, one for each year of students: S08, S09, and S10. The file \"question_answer_pairs.txt\" contains the questions and answers. The first line of the file contains \r\n",
        "column names for the tab-separated data fields in the file. This first line follows:\r\n",
        "\r\n",
        "We will extract the question and answers from all the three files and concatenate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGE6as9s23FW",
        "outputId": "6d37a4d0-a05b-48b3-f171-c4b328698e02"
      },
      "source": [
        "df1 = pd.read_csv(\"./Question_Answer_Dataset_v1.2/S08/question_answer_pairs.txt\",sep=\"\\t\",engine='python')\r\n",
        "df2 = pd.read_csv(\"./Question_Answer_Dataset_v1.2/S09/question_answer_pairs.txt\",sep=\"\\t\",engine='python')\r\n",
        "df3 = pd.read_csv(\"./Question_Answer_Dataset_v1.2/S10/question_answer_pairs.txt\",sep=\"\\t\",engine='python',quotechar='\"', error_bad_lines=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping line 765: '\t' expected after '\"'\n",
            "Skipping line 876: '\t' expected after '\"'\n",
            "Skipping line 1219: '\t' expected after '\"'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMz8avsr3-EB"
      },
      "source": [
        "df = pd.concat([df1, df2, df3], axis=0, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "7xHeurgBfqdY",
        "outputId": "21a74966-d007-4a72-9f1b-6656fe047913"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ArticleTitle</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>DifficultyFromQuestioner</th>\n",
              "      <th>DifficultyFromAnswerer</th>\n",
              "      <th>ArticleFile</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
              "      <td>yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>medium</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Did his mother die of pneumonia?</td>\n",
              "      <td>no</td>\n",
              "      <td>easy</td>\n",
              "      <td>medium</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ArticleTitle  ...   ArticleFile\n",
              "0  Abraham_Lincoln  ...  data/set3/a4\n",
              "1  Abraham_Lincoln  ...  data/set3/a4\n",
              "2  Abraham_Lincoln  ...  data/set3/a4\n",
              "3  Abraham_Lincoln  ...  data/set3/a4\n",
              "4  Abraham_Lincoln  ...  data/set3/a4\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSYcUJQawJ7D",
        "outputId": "621d3df5-e07e-401a-bb5e-e88e99906620"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3995 entries, 0 to 3994\n",
            "Data columns (total 6 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   ArticleTitle              3995 non-null   object\n",
            " 1   Question                  3958 non-null   object\n",
            " 2   Answer                    3419 non-null   object\n",
            " 3   DifficultyFromQuestioner  3041 non-null   object\n",
            " 4   DifficultyFromAnswerer    3415 non-null   object\n",
            " 5   ArticleFile               3993 non-null   object\n",
            "dtypes: object(6)\n",
            "memory usage: 187.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqoiwZwk9Uya"
      },
      "source": [
        "Drop the rows which contains nulls values in Question and Answer columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "MlnGJCpxvr0T",
        "outputId": "cd0c811e-6542-4059-b745-03e09ffe3869"
      },
      "source": [
        "df.dropna(subset=['Question','Answer'], inplace=True)\r\n",
        "df.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ArticleTitle</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>DifficultyFromQuestioner</th>\n",
              "      <th>DifficultyFromAnswerer</th>\n",
              "      <th>ArticleFile</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
              "      <td>yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>medium</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Did his mother die of pneumonia?</td>\n",
              "      <td>no</td>\n",
              "      <td>easy</td>\n",
              "      <td>medium</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3414</th>\n",
              "      <td>Zebra</td>\n",
              "      <td>What areas do the Grevy's Zebras inhabit?</td>\n",
              "      <td>semi-arid grasslands of Ethiopia and northern ...</td>\n",
              "      <td>hard</td>\n",
              "      <td>hard</td>\n",
              "      <td>data/set1/a9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3415</th>\n",
              "      <td>Zebra</td>\n",
              "      <td>Which species of zebra is known as the common ...</td>\n",
              "      <td>Plains Zebra (Equus quagga, formerly Equus bur...</td>\n",
              "      <td>hard</td>\n",
              "      <td>medium</td>\n",
              "      <td>data/set1/a9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3416</th>\n",
              "      <td>Zebra</td>\n",
              "      <td>Which species of zebra is known as the common ...</td>\n",
              "      <td>Plains Zebra</td>\n",
              "      <td>hard</td>\n",
              "      <td>medium</td>\n",
              "      <td>data/set1/a9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3417</th>\n",
              "      <td>Zebra</td>\n",
              "      <td>At what age can a zebra breed?</td>\n",
              "      <td>five or six</td>\n",
              "      <td>hard</td>\n",
              "      <td>medium</td>\n",
              "      <td>data/set1/a9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3418</th>\n",
              "      <td>Zebra</td>\n",
              "      <td>At what age can a zebra breed?</td>\n",
              "      <td>5 or 6</td>\n",
              "      <td>hard</td>\n",
              "      <td>hard</td>\n",
              "      <td>data/set1/a9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3419 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ArticleTitle  ...   ArticleFile\n",
              "0     Abraham_Lincoln  ...  data/set3/a4\n",
              "1     Abraham_Lincoln  ...  data/set3/a4\n",
              "2     Abraham_Lincoln  ...  data/set3/a4\n",
              "3     Abraham_Lincoln  ...  data/set3/a4\n",
              "4     Abraham_Lincoln  ...  data/set3/a4\n",
              "...               ...  ...           ...\n",
              "3414            Zebra  ...  data/set1/a9\n",
              "3415            Zebra  ...  data/set1/a9\n",
              "3416            Zebra  ...  data/set1/a9\n",
              "3417            Zebra  ...  data/set1/a9\n",
              "3418            Zebra  ...  data/set1/a9\n",
              "\n",
              "[3419 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXN0QPGzz0N4",
        "outputId": "a3a0e6bd-c1ad-4494-b3aa-c06acf7f3a02"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3419 entries, 0 to 3994\n",
            "Data columns (total 6 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   ArticleTitle              3419 non-null   object\n",
            " 1   Question                  3419 non-null   object\n",
            " 2   Answer                    3419 non-null   object\n",
            " 3   DifficultyFromQuestioner  2732 non-null   object\n",
            " 4   DifficultyFromAnswerer    3414 non-null   object\n",
            " 5   ArticleFile               3417 non-null   object\n",
            "dtypes: object(6)\n",
            "memory usage: 187.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc_xZXxJfvoS"
      },
      "source": [
        "# Import Library\r\n",
        "import random\r\n",
        "import torch, torchtext\r\n",
        "from torchtext import data \r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "from torchtext.data import Field, BucketIterator\r\n",
        "import spacy\r\n",
        "import numpy as np\r\n",
        "import math\r\n",
        "import time\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.ticker as ticker\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLrxIDu8gH4n"
      },
      "source": [
        "#Then set a random seed for deterministic results/reproducability.\r\n",
        "SEED = 1234\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.cuda.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIqiCwLi9ziA"
      },
      "source": [
        "Create our fields to process our data. This will append the \"start of sentence\" and \"end of sentence\" tokens as well as converting all words to lowercase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPLXQgHHf1jN"
      },
      "source": [
        "SRC= data.Field(sequential = True, tokenize = 'spacy',init_token='<sos>', \r\n",
        "            eos_token='<eos>', \r\n",
        "            lower=True)\r\n",
        "TRG = data.Field(sequential = True, tokenize = 'spacy',init_token='<sos>', \r\n",
        "            eos_token='<eos>', \r\n",
        "            lower=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oFGBpLD-SWN"
      },
      "source": [
        "Having defined those fields, we now need to produce a list that maps them onto the list of rows that are in the CSV:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRu2G06Uu9NT"
      },
      "source": [
        "fields = [('Question', SRC),('Answer',TRG)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "456Hn8XE-f0Y"
      },
      "source": [
        "Armed with our declared fields, lets convert from pandas to list to torchtext. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-TlfW5lvDMP"
      },
      "source": [
        "example = [data.Example.fromlist([df.Question.iloc[i],df.Answer.iloc[i]], fields) for i in range(df.shape[0])] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEBSbtg--kLP"
      },
      "source": [
        "Creating dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgRNKj2FvNq0"
      },
      "source": [
        "QnADataset = data.Dataset(example, fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00Dba1Gi-woo"
      },
      "source": [
        "Finally, we can split into training, testing, and validation sets by using the split() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu7F8QEr0hPI"
      },
      "source": [
        "(train_data, valid_data,test_data) = QnADataset.split(split_ratio=[0.80, 0.10,0.10], random_state=random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPnEo75S0tt4",
        "outputId": "d842a083-6074-428a-bc48-775c12d706e2"
      },
      "source": [
        "(len(train_data), len(valid_data),len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2735, 342, 342)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmFSDM4S07xn",
        "outputId": "cc8d0e4d-7a59-4b9e-df7e-3851041f0672"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Question': ['was', 'mission', 'bay', 'campus', 'opened', 'in', '2003'], 'Answer': ['yes']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxX5mgk2-8VB"
      },
      "source": [
        "Then create our vocabulary, converting all tokens appearing less than twice into <unk> tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpDtuN2p0-K-"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\r\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8EUkcBO--z-"
      },
      "source": [
        "Finally, define the device and create our iterators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-UvpKXg1AkT"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A19rx2ur1DZ9"
      },
      "source": [
        "BATCH_SIZE = 32\r\n",
        "\r\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\r\n",
        "    (train_data, valid_data, test_data), \r\n",
        "    batch_size = BATCH_SIZE,\r\n",
        "    sort_key=lambda x : len(x.Question),\r\n",
        "    sort_within_batch=False, \r\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVKknZPIER7g"
      },
      "source": [
        "### Building the Seq2Seq Model\r\n",
        "\r\n",
        "\r\n",
        "This is the first model where we don't have to have the encoder RNN and decoder RNN have the same hidden dimensions, however the encoder has to be bidirectional. This requirement can be removed by changing all occurences of `enc_dim * 2` to `enc_dim * 2 if encoder_is_bidirectional else enc_dim`. \r\n",
        "\r\n",
        "This seq2seq encapsulator is similar to the last two. The only difference is that the `encoder` returns both the final hidden state (which is the final hidden state from both the forward and backward encoder RNNs passed through a linear layer) to be used as the initial hidden state for the decoder, as well as every hidden state (which are the forward and backward hidden states stacked on top of each other). We also need to ensure that `hidden` and `encoder_outputs` are passed to the decoder. \r\n",
        "\r\n",
        "Briefly going over all of the steps:\r\n",
        "- the `outputs` tensor is created to hold all predictions, $\\hat{Y}$\r\n",
        "- the source sequence, $X$, is fed into the encoder to receive $z$ and $H$\r\n",
        "- the initial decoder hidden state is set to be the `context` vector, $s_0 = z = h_T$\r\n",
        "- we use a batch of `<sos>` tokens as the first `input`, $y_1$\r\n",
        "- we then decode within a loop:\r\n",
        "  - inserting the input token $y_t$, previous hidden state, $s_{t-1}$, and all encoder outputs, $H$, into the decoder\r\n",
        "  - receiving a prediction, $\\hat{y}_{t+1}$, and a new hidden state, $s_t$\r\n",
        "  - we then decide if we are going to teacher force or not, setting the next input as **appropriate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYeZdiaO1O5x"
      },
      "source": [
        "class Seq2Seq(nn.Module):\r\n",
        "    def __init__(self, encoder, decoder, device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.encoder = encoder\r\n",
        "        self.decoder = decoder\r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\r\n",
        "        \r\n",
        "        #src = [src len, batch size]\r\n",
        "        #trg = [trg len, batch size]\r\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\r\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\r\n",
        "        \r\n",
        "        batch_size = src.shape[1]\r\n",
        "        trg_len = trg.shape[0]\r\n",
        "        trg_vocab_size = self.decoder.output_dim\r\n",
        "        \r\n",
        "        #tensor to store decoder outputs\r\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\r\n",
        "        \r\n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\r\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\r\n",
        "        encoder_outputs, hidden = self.encoder(src)\r\n",
        "                \r\n",
        "        #first input to the decoder is the <sos> tokens\r\n",
        "        input = trg[0,:]\r\n",
        "        \r\n",
        "        for t in range(1, trg_len):\r\n",
        "            \r\n",
        "            #insert input token embedding, previous hidden state and all encoder hidden states\r\n",
        "            #receive output tensor (predictions) and new hidden state\r\n",
        "            output, hidden,_ = self.decoder(input, hidden, encoder_outputs)\r\n",
        "            \r\n",
        "            #place predictions in a tensor holding predictions for each token\r\n",
        "            outputs[t] = output\r\n",
        "            \r\n",
        "            #decide if we are going to use teacher forcing or not\r\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\r\n",
        "            \r\n",
        "            #get the highest predicted token from our predictions\r\n",
        "            top1 = output.argmax(1) \r\n",
        "            \r\n",
        "            #if teacher forcing, use actual next token as next input\r\n",
        "            #if not, use predicted token\r\n",
        "            input = trg[t] if teacher_force else top1\r\n",
        "\r\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOk39y21_C_w"
      },
      "source": [
        "\r\n",
        "### Encoder\r\n",
        "\r\n",
        "First, we'll build the encoder. Similar to the previous model, we only use a single layer GRU, however we now use a *bidirectional RNN*. With a bidirectional RNN, we have two RNNs in each layer. A *forward RNN* going over the embedded sentence from left to right (shown below in green), and a *backward RNN* going over the embedded sentence from right to left (teal). All we need to do in code is set `bidirectional = True` and then pass the embedded sentence to the RNN as before. \r\n",
        "\r\n",
        "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq8.png?raw=1)\r\n",
        "\r\n",
        "We now have:\r\n",
        "\r\n",
        "$$\\begin{align*}\r\n",
        "h_t^\\rightarrow &= \\text{EncoderGRU}^\\rightarrow(e(x_t^\\rightarrow),h_{t-1}^\\rightarrow)\\\\\r\n",
        "h_t^\\leftarrow &= \\text{EncoderGRU}^\\leftarrow(e(x_t^\\leftarrow),h_{t-1}^\\leftarrow)\r\n",
        "\\end{align*}$$\r\n",
        "\r\n",
        "Where $x_0^\\rightarrow = \\text{<sos>}, x_1^\\rightarrow = \\text{guten}$ and $x_0^\\leftarrow = \\text{<eos>}, x_1^\\leftarrow = \\text{morgen}$.\r\n",
        "\r\n",
        "As before, we only pass an input (`embedded`) to the RNN, which tells PyTorch to initialize both the forward and backward initial hidden states ($h_0^\\rightarrow$ and $h_0^\\leftarrow$, respectively) to a tensor of all zeros. We'll also get two context vectors, one from the forward RNN after it has seen the final word in the sentence, $z^\\rightarrow=h_T^\\rightarrow$, and one from the backward RNN after it has seen the first word in the sentence, $z^\\leftarrow=h_T^\\leftarrow$.\r\n",
        "\r\n",
        "The RNN returns `outputs` and `hidden`. \r\n",
        "\r\n",
        "`outputs` is of size **[src len, batch size, hid dim * num directions]** where the first `hid_dim` elements in the third axis are the hidden states from the top layer forward RNN, and the last `hid_dim` elements are hidden states from the top layer backward RNN. We can think of the third axis as being the forward and backward hidden states concatenated together other, i.e. $h_1 = [h_1^\\rightarrow; h_{T}^\\leftarrow]$, $h_2 = [h_2^\\rightarrow; h_{T-1}^\\leftarrow]$ and we can denote all encoder hidden states (forward and backwards concatenated together) as $H=\\{ h_1, h_2, ..., h_T\\}$.\r\n",
        "\r\n",
        "`hidden` is of size **[n layers * num directions, batch size, hid dim]**, where **[-2, :, :]** gives the top layer forward RNN hidden state after the final time-step (i.e. after it has seen the last word in the sentence) and **[-1, :, :]** gives the top layer backward RNN hidden state after the final time-step (i.e. after it has seen the first word in the sentence).\r\n",
        "\r\n",
        "As the decoder is not bidirectional, it only needs a single context vector, $z$, to use as its initial hidden state, $s_0$, and we currently have two, a forward and a backward one ($z^\\rightarrow=h_T^\\rightarrow$ and $z^\\leftarrow=h_T^\\leftarrow$, respectively). We solve this by concatenating the two context vectors together, passing them through a linear layer, $g$, and applying the $\\tanh$ activation function. \r\n",
        "\r\n",
        "$$z=\\tanh(g(h_T^\\rightarrow, h_T^\\leftarrow)) = \\tanh(g(z^\\rightarrow, z^\\leftarrow)) = s_0$$\r\n",
        "\r\n",
        "**Note**: this is actually a deviation from the paper. Instead, they feed only the first backward RNN hidden state through a linear layer to get the context vector/decoder initial hidden state. This doesn't seem to make sense to me, so we have changed it.\r\n",
        "\r\n",
        "As we want our model to look back over the whole of the source sentence we return `outputs`, the stacked forward and backward hidden states for every token in the source sentence. We also return `hidden`, which acts as our initial hidden state in the decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMS-S2L61IHE"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\r\n",
        "        \r\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\r\n",
        "        \r\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, src):\r\n",
        "        \r\n",
        "        #src = [src len, batch size]\r\n",
        "        \r\n",
        "        embedded = self.dropout(self.embedding(src))\r\n",
        "        \r\n",
        "        #embedded = [src len, batch size, emb dim]\r\n",
        "        \r\n",
        "        outputs, hidden = self.rnn(embedded)\r\n",
        "                \r\n",
        "        #outputs = [src len, batch size, hid dim * num directions]\r\n",
        "        #hidden = [n layers * num directions, batch size, hid dim]\r\n",
        "        \r\n",
        "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\r\n",
        "        #outputs are always from the last layer\r\n",
        "        \r\n",
        "        #hidden [-2, :, : ] is the last of the forwards RNN \r\n",
        "        #hidden [-1, :, : ] is the last of the backwards RNN\r\n",
        "        \r\n",
        "        #initial decoder hidden is final hidden state of the forwards and backwards \r\n",
        "        #  encoder RNNs fed through a linear layer\r\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\r\n",
        "        \r\n",
        "        #outputs = [src len, batch size, enc hid dim * 2]\r\n",
        "        #hidden = [batch size, dec hid dim]\r\n",
        "        \r\n",
        "        return outputs, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiPrXt98_Kqy"
      },
      "source": [
        "### Attention\r\n",
        "\r\n",
        "Next up is the attention layer. This will take in the previous hidden state of the decoder, $s_{t-1}$, and all of the stacked forward and backward hidden states from the encoder, $H$. The layer will output an attention vector, $a_t$, that is the length of the source sentence, each element is between 0 and 1 and the entire vector sums to 1.\r\n",
        "\r\n",
        "Intuitively, this layer takes what we have decoded so far, $s_{t-1}$, and all of what we have encoded, $H$, to produce a vector, $a_t$, that represents which words in the source sentence we should pay the most attention to in order to correctly predict the next word to decode, $\\hat{y}_{t+1}$. \r\n",
        "\r\n",
        "First, we calculate the *energy* between the previous decoder hidden state and the encoder hidden states. As our encoder hidden states are a sequence of $T$ tensors, and our previous decoder hidden state is a single tensor, the first thing we do is `repeat` the previous decoder hidden state $T$ times. We then calculate the energy, $E_t$, between them by concatenating them together and passing them through a linear layer (`attn`) and a $\\tanh$ activation function. \r\n",
        "\r\n",
        "$$E_t = \\tanh(\\text{attn}(s_{t-1}, H))$$ \r\n",
        "\r\n",
        "This can be thought of as calculating how well each encoder hidden state \"matches\" the previous decoder hidden state.\r\n",
        "\r\n",
        "We currently have a **[dec hid dim, src len]** tensor for each example in the batch. We want this to be **[src len]** for each example in the batch as the attention should be over the length of the source sentence. This is achieved by multiplying the `energy` by a **[1, dec hid dim]** tensor, $v$.\r\n",
        "\r\n",
        "$$\\hat{a}_t = v E_t$$\r\n",
        "\r\n",
        "We can think of $v$ as the weights for a weighted sum of the energy across all encoder hidden states. These weights tell us how much we should attend to each token in the source sequence. The parameters of $v$ are initialized randomly, but learned with the rest of the model via backpropagation. Note how $v$ is not dependent on time, and the same $v$ is used for each time-step of the decoding. We implement $v$ as a linear layer without a bias.\r\n",
        "\r\n",
        "Finally, we ensure the attention vector fits the constraints of having all elements between 0 and 1 and the vector summing to 1 by passing it through a $\\text{softmax}$ layer.\r\n",
        "\r\n",
        "$$a_t = \\text{softmax}(\\hat{a_t})$$\r\n",
        "\r\n",
        "This gives us the attention over the source sentence!\r\n",
        "\r\n",
        "Graphically, this looks something like below. This is for calculating the very first attention vector, where $s_{t-1} = s_0 = z$. The green/teal blocks represent the hidden states from both the forward and backward RNNs, and the attention computation is all done within the pink block.\r\n",
        "\r\n",
        "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq9.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suh4d6hiEG7H"
      },
      "source": [
        "class Attention(nn.Module):\r\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\r\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\r\n",
        "        \r\n",
        "    def forward(self, hidden, encoder_outputs):\r\n",
        "        \r\n",
        "        #hidden = [batch size, dec hid dim]\r\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\r\n",
        "        \r\n",
        "        batch_size = encoder_outputs.shape[1]\r\n",
        "        src_len = encoder_outputs.shape[0]\r\n",
        "        \r\n",
        "        #repeat decoder hidden state src_len times\r\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\r\n",
        "        \r\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\r\n",
        "        \r\n",
        "        #hidden = [batch size, src len, dec hid dim]\r\n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\r\n",
        "        \r\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \r\n",
        "        \r\n",
        "        #energy = [batch size, src len, dec hid dim]\r\n",
        "\r\n",
        "        attention = self.v(energy).squeeze(2)\r\n",
        "        \r\n",
        "        #attention= [batch size, src len]\r\n",
        "        \r\n",
        "        return F.softmax(attention, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDA03_cM_QVp"
      },
      "source": [
        "### Decoder\r\n",
        "\r\n",
        "Next up is the decoder. \r\n",
        "\r\n",
        "The decoder contains the attention layer, `attention`, which takes the previous hidden state, $s_{t-1}$, all of the encoder hidden states, $H$, and returns the attention vector, $a_t$.\r\n",
        "\r\n",
        "We then use this attention vector to create a weighted source vector, $w_t$, denoted by `weighted`, which is a weighted sum of the encoder hidden states, $H$, using $a_t$ as the weights.\r\n",
        "\r\n",
        "$$w_t = a_t H$$\r\n",
        "\r\n",
        "The embedded input word, $d(y_t)$, the weighted source vector, $w_t$, and the previous decoder hidden state, $s_{t-1}$, are then all passed into the decoder RNN, with $d(y_t)$ and $w_t$ being concatenated together.\r\n",
        "\r\n",
        "$$s_t = \\text{DecoderGRU}(d(y_t), w_t, s_{t-1})$$\r\n",
        "\r\n",
        "We then pass $d(y_t)$, $w_t$ and $s_t$ through the linear layer, $f$, to make a prediction of the next word in the target sentence, $\\hat{y}_{t+1}$. This is done by concatenating them all together.\r\n",
        "\r\n",
        "$$\\hat{y}_{t+1} = f(d(y_t), w_t, s_t)$$\r\n",
        "\r\n",
        "The image below shows decoding the first word in an example translation.\r\n",
        "\r\n",
        "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq10.png?raw=1)\r\n",
        "\r\n",
        "The green/teal blocks show the forward/backward encoder RNNs which output $H$, the red block shows the context vector, $z = h_T = \\tanh(g(h^\\rightarrow_T,h^\\leftarrow_T)) = \\tanh(g(z^\\rightarrow, z^\\leftarrow)) = s_0$, the blue block shows the decoder RNN which outputs $s_t$, the purple block shows the linear layer, $f$, which outputs $\\hat{y}_{t+1}$ and the orange block shows the calculation of the weighted sum over $H$ by $a_t$ and outputs $w_t$. Not shown is the calculation of $a_t$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spy0krTg1NUo"
      },
      "source": [
        "class Decoder(nn.Module):\r\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.output_dim = output_dim\r\n",
        "        self.attention = attention\r\n",
        "        \r\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\r\n",
        "        \r\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\r\n",
        "        \r\n",
        "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, input, hidden, encoder_outputs):\r\n",
        "             \r\n",
        "        #input = [batch size]\r\n",
        "        #hidden = [batch size, dec hid dim]\r\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\r\n",
        "        \r\n",
        "        input = input.unsqueeze(0)\r\n",
        "        \r\n",
        "        #input = [1, batch size]\r\n",
        "        \r\n",
        "        embedded = self.dropout(self.embedding(input))\r\n",
        "        \r\n",
        "        #embedded = [1, batch size, emb dim]\r\n",
        "        \r\n",
        "        a = self.attention(hidden, encoder_outputs)\r\n",
        "                \r\n",
        "        #a = [batch size, src len]\r\n",
        "        \r\n",
        "        a = a.unsqueeze(1)\r\n",
        "        \r\n",
        "        #a = [batch size, 1, src len]\r\n",
        "        \r\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\r\n",
        "        \r\n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\r\n",
        "        \r\n",
        "        weighted = torch.bmm(a, encoder_outputs)\r\n",
        "        \r\n",
        "        #weighted = [batch size, 1, enc hid dim * 2]\r\n",
        "        \r\n",
        "        weighted = weighted.permute(1, 0, 2)\r\n",
        "        \r\n",
        "        #weighted = [1, batch size, enc hid dim * 2]\r\n",
        "        \r\n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\r\n",
        "        \r\n",
        "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\r\n",
        "            \r\n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\r\n",
        "        \r\n",
        "        #output = [seq len, batch size, dec hid dim * n directions]\r\n",
        "        #hidden = [n layers * n directions, batch size, dec hid dim]\r\n",
        "        \r\n",
        "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\r\n",
        "        #output = [1, batch size, dec hid dim]\r\n",
        "        #hidden = [1, batch size, dec hid dim]\r\n",
        "        #this also means that output == hidden\r\n",
        "        assert (output == hidden).all()\r\n",
        "        \r\n",
        "        embedded = embedded.squeeze(0)\r\n",
        "        output = output.squeeze(0)\r\n",
        "        weighted = weighted.squeeze(0)\r\n",
        "        \r\n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\r\n",
        "        \r\n",
        "        #prediction = [batch size, output dim]\r\n",
        "        \r\n",
        "        return prediction, hidden.squeeze(0),a.squeeze(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMHSG524_WCr"
      },
      "source": [
        "# Training the Seq2Seq Model\r\n",
        "\r\n",
        "We initialise our encoder, decoder and seq2seq model (placing it on the GPU if we have one). The embedding dimensions and the amount of dropout used can be different between the encoder and the decoder, but the hidden dimensions must remain the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftEpd_4a1QmF"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\r\n",
        "OUTPUT_DIM = len(TRG.vocab)\r\n",
        "ENC_EMB_DIM = 256\r\n",
        "DEC_EMB_DIM = 256\r\n",
        "ENC_HID_DIM = 512\r\n",
        "DEC_HID_DIM = 512\r\n",
        "ENC_DROPOUT = 0.5\r\n",
        "DEC_DROPOUT = 0.5\r\n",
        "\r\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\r\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\r\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\r\n",
        "\r\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8nTb43V_Zyo"
      },
      "source": [
        "We use a simplified version of the weight initialization scheme used in the paper. Here, we will initialize all biases to zero and all weights from  N(0,0.01) ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMp_2W9S1SVR",
        "outputId": "2f420121-6ed8-42f0-de3c-f3f22f6a3ba0"
      },
      "source": [
        "def init_weights(m):\r\n",
        "    for name, param in m.named_parameters():\r\n",
        "        nn.init.normal_(param.data, mean=0, std=0.01)\r\n",
        "        \r\n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(2197, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(1504, 256)\n",
              "    (rnn): GRU(1280, 512)\n",
              "    (fc_out): Linear(in_features=1792, out_features=1504, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5_2i7Dk_fdz"
      },
      "source": [
        "We print out the number of parameters.\r\n",
        "\r\n",
        "Calculate the number of parameters. We get an increase of almost 50% in the amount of parameters from the last model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Enkgnath1Tt3",
        "outputId": "0c3bb875-6955-4169-ded4-0023422a27a7"
      },
      "source": [
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 10,077,408 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH3WH5Lh_mPO"
      },
      "source": [
        "We initiaize our optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUoyH79C1W7L"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Khbcq7R4_p-w"
      },
      "source": [
        "We also initialize the loss function, making sure to ignore the loss on `<pad>` tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFiHkSJC1YWm"
      },
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tuZ-o3l_xKO"
      },
      "source": [
        "We then create the training loop..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GeuBp3t1ZiB"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\r\n",
        "    \r\n",
        "    model.train()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    for i, batch in enumerate(iterator):\r\n",
        "        \r\n",
        "        src = batch.Question\r\n",
        "        trg = batch.Answer\r\n",
        "        \r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        output = model(src, trg)\r\n",
        "        \r\n",
        "        #trg = [trg len, batch size]\r\n",
        "        #output = [trg len, batch size, output dim]\r\n",
        "        \r\n",
        "        output_dim = output.shape[-1]\r\n",
        "        \r\n",
        "        output = output[1:].view(-1, output_dim)\r\n",
        "        trg = trg[1:].view(-1)\r\n",
        "        \r\n",
        "        #trg = [(trg len - 1) * batch size]\r\n",
        "        #output = [(trg len - 1) * batch size, output dim]\r\n",
        "        \r\n",
        "        loss = criterion(output, trg)\r\n",
        "        \r\n",
        "        loss.backward()\r\n",
        "        \r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\r\n",
        "        \r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        epoch_loss += loss.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OMTod0P_2I9"
      },
      "source": [
        "...and the evaluation loop, remembering to set the model to eval mode and turn off teaching forcing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3z3OEyq1byl"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "    \r\n",
        "        for i, batch in enumerate(iterator):\r\n",
        "\r\n",
        "            src = batch.Question\r\n",
        "            trg = batch.Answer\r\n",
        "\r\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\r\n",
        "\r\n",
        "            #trg = [trg len, batch size]\r\n",
        "            #output = [trg len, batch size, output dim]\r\n",
        "\r\n",
        "            output_dim = output.shape[-1]\r\n",
        "            \r\n",
        "            output = output[1:].view(-1, output_dim)\r\n",
        "            trg = trg[1:].view(-1)\r\n",
        "\r\n",
        "            #trg = [(trg len - 1) * batch size]\r\n",
        "            #output = [(trg len - 1) * batch size, output dim]\r\n",
        "\r\n",
        "            loss = criterion(output, trg)\r\n",
        "\r\n",
        "            epoch_loss += loss.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjycjEXz_6h4"
      },
      "source": [
        "We'll also define the function that calculates how long an epoch takes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkH2vb6z1drm"
      },
      "source": [
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuTL4wYQ_8-W"
      },
      "source": [
        "Then, we train our model, saving the parameters that give us the best validation loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGldAX9N1e_8",
        "outputId": "2cf39d14-3043-4ccf-cffd-f19ab5e292ea"
      },
      "source": [
        "N_EPOCHS = 10\r\n",
        "CLIP = 1\r\n",
        "\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "    \r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\r\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\r\n",
        "    \r\n",
        "    end_time = time.time()\r\n",
        "    \r\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "    \r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 8s\n",
            "\tTrain Loss: 4.988 | Train PPL: 146.642\n",
            "\t Val. Loss: 3.802 |  Val. PPL:  44.788\n",
            "Epoch: 02 | Time: 0m 8s\n",
            "\tTrain Loss: 4.286 | Train PPL:  72.709\n",
            "\t Val. Loss: 3.696 |  Val. PPL:  40.294\n",
            "Epoch: 03 | Time: 0m 8s\n",
            "\tTrain Loss: 4.115 | Train PPL:  61.235\n",
            "\t Val. Loss: 3.700 |  Val. PPL:  40.465\n",
            "Epoch: 04 | Time: 0m 8s\n",
            "\tTrain Loss: 3.936 | Train PPL:  51.189\n",
            "\t Val. Loss: 3.618 |  Val. PPL:  37.270\n",
            "Epoch: 05 | Time: 0m 8s\n",
            "\tTrain Loss: 3.675 | Train PPL:  39.443\n",
            "\t Val. Loss: 3.593 |  Val. PPL:  36.357\n",
            "Epoch: 06 | Time: 0m 8s\n",
            "\tTrain Loss: 3.395 | Train PPL:  29.824\n",
            "\t Val. Loss: 3.558 |  Val. PPL:  35.098\n",
            "Epoch: 07 | Time: 0m 8s\n",
            "\tTrain Loss: 3.094 | Train PPL:  22.058\n",
            "\t Val. Loss: 3.543 |  Val. PPL:  34.575\n",
            "Epoch: 08 | Time: 0m 8s\n",
            "\tTrain Loss: 2.770 | Train PPL:  15.961\n",
            "\t Val. Loss: 3.538 |  Val. PPL:  34.403\n",
            "Epoch: 09 | Time: 0m 8s\n",
            "\tTrain Loss: 2.453 | Train PPL:  11.628\n",
            "\t Val. Loss: 3.541 |  Val. PPL:  34.486\n",
            "Epoch: 10 | Time: 0m 8s\n",
            "\tTrain Loss: 2.214 | Train PPL:   9.152\n",
            "\t Val. Loss: 3.581 |  Val. PPL:  35.895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTCrvQ3-ADUe"
      },
      "source": [
        "Finally, we test the model on the test set using these \"best\" parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wODowUY1hHo",
        "outputId": "01c71f47-fad1-4a2a-f2a5-af9fd2abd450"
      },
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\r\n",
        "\r\n",
        "test_loss = evaluate(model, test_iterator, criterion)\r\n",
        "\r\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 3.439 | Test PPL:  31.145 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kZXSc5SAGiG"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtCVL3y_FRg9"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "        \r\n",
        "    if isinstance(sentence, str):\r\n",
        "        nlp = spacy.load('de')\r\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\r\n",
        "    else:\r\n",
        "        tokens = [token.lower() for token in sentence]\r\n",
        "\r\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\r\n",
        "        \r\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\r\n",
        "    \r\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\r\n",
        "\r\n",
        "    # src_len = torch.LongTensor([len(src_indexes)]).to(device)\r\n",
        "    # src_len=src_len.cpu()\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "        encoder_outputs, hidden = model.encoder(src_tensor)\r\n",
        "\r\n",
        "    # mask = model.create_mask(src_tensor)\r\n",
        "        \r\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\r\n",
        "\r\n",
        "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\r\n",
        "    \r\n",
        "    for i in range(max_len):\r\n",
        "\r\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\r\n",
        "                \r\n",
        "        with torch.no_grad():\r\n",
        "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs)\r\n",
        "\r\n",
        "        attentions[i] = attention\r\n",
        "            \r\n",
        "        pred_token = output.argmax(1).item()\r\n",
        "        \r\n",
        "        trg_indexes.append(pred_token)\r\n",
        "\r\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\r\n",
        "            break\r\n",
        "    \r\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\r\n",
        "    \r\n",
        "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0dQmNUbhpUS"
      },
      "source": [
        "def display_attention(sentence, translation, attention):\r\n",
        "    \r\n",
        "    fig = plt.figure(figsize=(10,10))\r\n",
        "    ax = fig.add_subplot(111)\r\n",
        "    \r\n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\r\n",
        "    \r\n",
        "    cax = ax.matshow(attention, cmap='bone')\r\n",
        "   \r\n",
        "    ax.tick_params(labelsize=15)\r\n",
        "    ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \r\n",
        "                       rotation=45)\r\n",
        "    ax.set_yticklabels(['']+translation)\r\n",
        "\r\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "\r\n",
        "    plt.show()\r\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKuzxxT1hsly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b9d77d-2764-4b36-a080-46e56492fbc2"
      },
      "source": [
        "example_idx = 12\r\n",
        "\r\n",
        "src = vars(train_data.examples[example_idx])['Question']\r\n",
        "trg = vars(train_data.examples[example_idx])['Answer']\r\n",
        "\r\n",
        "print(f'question = {src}')\r\n",
        "print(f'answer = {trg}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "question = ['(', 'where', 'french', 'has', 'a', 'similar', 'phenomenon', ',', 'with', 'alveolar', 'affricates', 'instead', 'of', 'postalveolars', '?']\n",
            "answer = ['quebec', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gt7xxzEiHvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36b46bb3-d36b-4c67-9b6a-f04dfd1bd798"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
        "\r\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['<unk>', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9kVdU2RiLIF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "10b87f52-375b-4d1b-e3a4-bccd9aad10f4"
      },
      "source": [
        "display_attention(src, translation, attention)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB_E4upCiLxc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "846af8b1-7236-45e6-83b8-c918fbfe860a"
      },
      "source": [
        "example_idx = 14\r\n",
        "\r\n",
        "src = vars(train_data.examples[example_idx])['Question']\r\n",
        "trg = vars(train_data.examples[example_idx])['Answer']\r\n",
        "\r\n",
        "print(f'question = {src}')\r\n",
        "print(f'answer = {trg}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "question = ['where', 'do', 'sea', 'otters', 'live', '?']\n",
            "answer = ['sea', 'otters', '(', 'enhydra', 'lutris', ')', 'live', 'along', 'the', 'pacific', 'coast', 'of', 'north', 'america', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_obRBu8iPQK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "6213235a-39e3-465f-febe-3491b63a1355"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
        "\r\n",
        "print(f'predicted trg = {translation}')\r\n",
        "\r\n",
        "display_attention(src, translation, attention)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['pacific', 'otters', 'small', 'north', 'america', '<eos>']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_kGhz_3iRTf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "625941b1-686f-4bf5-c722-f54ba230119c"
      },
      "source": [
        "example_idx = 18\r\n",
        "\r\n",
        "src = vars(train_data.examples[example_idx])['Question']\r\n",
        "trg = vars(train_data.examples[example_idx])['Answer']\r\n",
        "\r\n",
        "print(f'question = {src}')\r\n",
        "print(f'answer = {trg}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "question = ['is', 'it', 'true', 'that', 'he', 'published', 'a', 'collection', 'in', '1738', '?']\n",
            "answer = ['no']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tN01BGYiV87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "78ae7798-7d98-4045-ad2f-03952fe4cf0e"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
        "\r\n",
        "print(f'predicted trg = {translation}')\r\n",
        "\r\n",
        "display_attention(src, translation, attention)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['yes', '<eos>']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}