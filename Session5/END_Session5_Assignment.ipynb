{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END_Session5_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "swHwLXOI9E7V"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divya-r-kamat/END/blob/main/Session5/END_Session5_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2uQSh7p2bM8",
        "outputId": "a078d67d-dda7-4922-fecc-042141b49905"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z-ET9kX2l1N",
        "outputId": "aea25f9e-5467-44cf-8812-26fbbaf7a45f"
      },
      "source": [
        "!ls drive/MyDrive/text.txt"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/MyDrive/text.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('drive/MyDrive/text.txt', 'r').read()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87a7ebcd-5912-43c6-e7b3-553864fec2db"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qi2XyeM82ce"
      },
      "source": [
        "# Hidden_Layer_size = 10 #size of the hidden layer\n",
        "# Time_steps = 10 # Number of time steps (length of the sequence) used for training\n",
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3HixUiAIiBe",
        "outputId": "e8873f13-8d61-4f42-c6df-b99eaa52151b"
      },
      "source": [
        "print(X_size)\n",
        "print(z_size)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75\n",
            "175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "  return  1 / (1 + np.exp(-x))\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return y * (1 - y) # write your code here\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  return np.tanh(x)# write your code here\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return 1 - y * y # write your code here"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKujZfJ-39If",
        "outputId": "c4f87198-f1c7-42ec-9e02-1a4e2dbbdcb3"
      },
      "source": [
        "print(sigmoid(0))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SfXS9v48MpG"
      },
      "source": [
        "---\n",
        "\n",
        "# Answer : 0.5\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK3sN7E54W8l"
      },
      "source": [
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PFz0DRf4C9f",
        "outputId": "9e9a2862-46ec-4e0d-c633-e45231037429"
      },
      "source": [
        "print(dsigmoid(sigmoid(0)))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFcixZEb8ZmV"
      },
      "source": [
        "---\n",
        "\n",
        "# Answer : 0.25\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvTHSwHK4U5H"
      },
      "source": [
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8WPETTo4JCd",
        "outputId": "8f89a6b2-1fdd-4fa4-ec8f-9fe7cd54b759"
      },
      "source": [
        "print(tanh(dsigmoid(sigmoid(0))))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.24491866240370913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqyrxaVj89T0"
      },
      "source": [
        "---\n",
        "\n",
        "# Answer : 0.24491\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09OUx57H4Vt5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iNoXo5A4Psp",
        "outputId": "bf7eeb40-54a7-4928-90aa-ccd4a3245274"
      },
      "source": [
        "print(dtanh(tanh(dsigmoid(sigmoid(0)))))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.940014848806378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzWuG5-m9GMD"
      },
      "source": [
        "---\n",
        "\n",
        "# Answer : 0.94001\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size # write your code here\n",
        "size_b = z_size# write your code here\n",
        "size_c = X_size # write your code here\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPz3bR1o9XC4"
      },
      "source": [
        "---\n",
        "\n",
        "# Answer :  size_a = Hidden_Layer_size , size_b = z_size, size_c = X_size\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
        "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
        "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
        "\n",
        "    C = f * C_prev + i * C_bar # write your code here\n",
        "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v) # write your code here\n",
        "    h = o * tanh(C) # write your code here\n",
        "\n",
        "    v = np.dot(p.W_v.v, h) + p.b_v.v# write your code here\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJPFjor-6M1f",
        "outputId": "60910532-7a96-4508-9669-38696c550737"
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMR34kJ-9uBK"
      },
      "source": [
        "---\n",
        "\n",
        "# Answer : 9\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBsRp7946Xi6",
        "outputId": "e120301c-f5ef-4781-d1d3-c532a109239e"
      },
      "source": [
        "print(z.shape)\n",
        "print(np.sum(z))\n",
        "print(np.sum(f))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(175, 1)\n",
            "0.0\n",
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjlVlFrQ97Ef"
      },
      "source": [
        "---\n",
        "\n",
        "# Answer : \n",
        "# print(z.shape) ===> (85,1)\n",
        "# print(np.sum(z)) ===> 0.0\n",
        "# print(np.sum(f)) ===> 5.0\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "ef05b723-a1d0-429c-eba6-57822bd219fe"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " do get traven with people which test restali. In 2003, Middcicati he sefecallt hast ads to the latest usd had ARe, Cantas, are mano ald stracd first a doten we ching respiratory infection sempalts of  \n",
            "----\n",
            "iter 49900, loss 5.676924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrkGye5fAJjX"
      },
      "source": [
        "---\n",
        "\n",
        "# Answer : Loss - 5.67\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG442tiZBnTz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}