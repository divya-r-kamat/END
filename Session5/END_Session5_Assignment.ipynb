{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END_Session5_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "swHwLXOI9E7V"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divya-r-kamat/END/blob/main/Session5/END_Session5_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2uQSh7p2bM8",
        "outputId": "da628bf6-0d2c-4db5-c10e-faf541181f88"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z-ET9kX2l1N",
        "outputId": "f03307fe-9e03-4777-af44-3075a4525ab4"
      },
      "source": [
        "!ls drive/MyDrive/text.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/MyDrive/text.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('drive/MyDrive/text.txt', 'r').read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3aa2f31-9257-472e-bf45-c09d32658ee2"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qi2XyeM82ce"
      },
      "source": [
        "# Hidden_Layer_size = 10 #size of the hidden layer\n",
        "# Time_steps = 10 # Number of time steps (length of the sequence) used for training\n",
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3HixUiAIiBe",
        "outputId": "a7bc0ad5-8b2b-4329-8ecd-00bdf4c67eeb"
      },
      "source": [
        "print(X_size)\n",
        "print(z_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75\n",
            "175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "  return  1 / (1 + np.exp(-x))\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return y * (1 - y) # write your code here\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  return np.tanh(x)# write your code here\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return 1 - y * y # write your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKujZfJ-39If",
        "outputId": "35c2d446-31a9-4708-d302-e39bcfc6aac3"
      },
      "source": [
        "print(sigmoid(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SfXS9v48MpG"
      },
      "source": [
        "---\n",
        "\n",
        "# Answer : 0.5\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK3sN7E54W8l"
      },
      "source": [
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PFz0DRf4C9f",
        "outputId": "f97e0085-f54e-45ca-eee8-7b032b54b458"
      },
      "source": [
        "print(dsigmoid(sigmoid(0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFcixZEb8ZmV"
      },
      "source": [
        "---\n",
        "\n",
        "# Answer : 0.25\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvTHSwHK4U5H"
      },
      "source": [
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8WPETTo4JCd",
        "outputId": "6fd106a2-ebfb-4dfb-b0b7-5088d7dea354"
      },
      "source": [
        "print(tanh(dsigmoid(sigmoid(0))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.24491866240370913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqyrxaVj89T0"
      },
      "source": [
        "---\n",
        "\n",
        "# Answer : 0.24491\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09OUx57H4Vt5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iNoXo5A4Psp",
        "outputId": "5075289e-d0df-4946-a7fd-42f382c11a6d"
      },
      "source": [
        "print(dtanh(tanh(dsigmoid(sigmoid(0)))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.940014848806378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzWuG5-m9GMD"
      },
      "source": [
        "---\n",
        "\n",
        "# Answer : 0.94001\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size # write your code here\n",
        "size_b = z_size# write your code here\n",
        "size_c = X_size # write your code here\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPz3bR1o9XC4"
      },
      "source": [
        "---\n",
        "\n",
        "# Answer :  size_a = Hidden_Layer_size , size_b = z_size, size_c = X_size\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
        "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
        "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
        "\n",
        "    C = f * C_prev + i * C_bar # write your code here\n",
        "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v) # write your code here\n",
        "    h = o * tanh(C) # write your code here\n",
        "\n",
        "    v = np.dot(p.W_v.v, h) + p.b_v.v# write your code here\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJPFjor-6M1f",
        "outputId": "7043c243-ba4d-42ac-b39d-c06f394ce7fd"
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMR34kJ-9uBK"
      },
      "source": [
        "---\n",
        "\n",
        "# Answer : 9\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBsRp7946Xi6",
        "outputId": "a6c0a357-5eb2-479e-e0ac-68323ecfef48"
      },
      "source": [
        "print(z.shape)\n",
        "print(np.sum(z))\n",
        "print(np.sum(f))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(175, 1)\n",
            "0.0\n",
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjlVlFrQ97Ef"
      },
      "source": [
        "---\n",
        "\n",
        "# Answer : \n",
        "# print(z.shape) ===> (85,1)\n",
        "# print(np.sum(z)) ===> 0.0\n",
        "# print(np.sum(f)) ===> 5.0\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "363a02a0-8c49-4435-ce67-336579625821"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " th officerininia, ethan at or a coro aways resialing to see hopes to the United Stavel best contecton. Wuhan, Wuhan, Ma, Direce sore nost cure now providuse, County offectimes about Health Orgdone in  \n",
            "----\n",
            "iter 49900, loss 6.061536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrkGye5fAJjX"
      },
      "source": [
        "---\n",
        "\n",
        "# Answer : Loss - 6.06\n",
        "\n",
        "---"
      ]
    }
  ]
}